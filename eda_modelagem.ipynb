{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXyR1B_h-E7E"
      },
      "outputs": [],
      "source": [
        "# Instalaçaõ duckdb mlflow plotly\n",
        "!pip install duckdb mlflow plotly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analise Exploratória\n"
      ],
      "metadata": {
        "id": "CIpSjiBlkrTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import duckdb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import TimeSeriesSplit\n"
      ],
      "metadata": {
        "id": "_VxbwK87-ipB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando dados\n",
        "consumo = pd.read_csv('/content/consumo.csv')\n",
        "clima = pd.read_csv('/content/clima.csv')\n",
        "clientes = pd.read_csv('/content/clientes.csv')"
      ],
      "metadata": {
        "id": "njl1sgTE-o_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando dados\n",
        "for df, name in zip([consumo, clima, clientes],\n",
        "                    ['consumo', 'clima', 'clientes']):\n",
        "    print(f\"\\n{name.upper()}\")\n",
        "    print(df.shape)\n",
        "    print(df.dtypes)\n",
        "    print(df.head())\n"
      ],
      "metadata": {
        "id": "XLoFaQEI-05X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando tipo de dados\n",
        "consumo['date'] = pd.to_datetime(consumo['date'])\n",
        "clima['date'] = pd.to_datetime(clima['date'])\n",
        "print(consumo.dtypes)\n",
        "print(clima.dtypes)\n"
      ],
      "metadata": {
        "id": "cPAL-uKi_VZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = consumo.sort_values(['client_id','date'])\n",
        "df_sorted['lag_1'] = df_sorted.groupby('client_id')['consumption_kwh'].shift(1)\n",
        "\n",
        "df_sorted[['consumption_kwh','lag_1']].corr()\n"
      ],
      "metadata": {
        "id": "RsLjSwcIos_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identificou-se forte dependência autoregressiva (ρ ≈ 0.64), indicando que modelos que incorporam histórico recente tendem a apresentar maior capacidade preditiva."
      ],
      "metadata": {
        "id": "mG-ZxT_dpCUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = consumo.merge(clientes, on='client_id')\n",
        "df = df.merge(clima, on=['region','date'])\n",
        "\n",
        "df[['consumption_kwh','temperature','humidity']].corr()\n"
      ],
      "metadata": {
        "id": "RiPtw-4rpIKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embora a correlação linear com temperatura seja baixa, variáveis climáticas foram mantidas como potenciais efeitos não lineares no modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "83uRBHssyeK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consumo_cliente = consumo.groupby('client_id')['consumption_kwh'].mean()\n",
        "\n",
        "print(\"Desvio padrão das médias:\", consumo_cliente.std())\n",
        "print(\"Mínimo:\", consumo_cliente.min())\n",
        "print(\"Máximo:\", consumo_cliente.max())\n"
      ],
      "metadata": {
        "id": "I_o24FO1k2fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observa-se significativa heterogeneidade estrutural entre clientes, com médias variando entre 9.4 e 19.4 kWh. O desvio padrão entre clientes (~3 kWh) é comparável à variabilidade diária da série, indicando que o perfil individual é um dos principais determinantes do consumo."
      ],
      "metadata": {
        "id": "ahUBOvaZzB70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "clima = clima.sort_values(['region','date'])\n",
        "\n",
        "clima['temperature'] = clima.groupby('region')['temperature'].transform(\n",
        "    lambda x: x.interpolate(method='linear')\n",
        ")\n"
      ],
      "metadata": {
        "id": "omvCnHVz_aAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.heatmap(clima.isnull(), cbar=False)\n",
        "plt.title(\"Mapa de Missing - Clima\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j5ZWVYqB_-rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A variável temperatura apresenta aproximadamente 5% de valores ausentes, distribuídos de forma esparsa ao longo da série, sem evidência de falhas estruturais concentradas por região ou período."
      ],
      "metadata": {
        "id": "rZfegEFtoDN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clima = clima.sort_values(['region','date'])\n",
        "\n",
        "clima['temperature'] = clima.groupby('region')['temperature'].transform(\n",
        "    lambda x: x.interpolate(method='linear')\n",
        ")\n",
        "\n",
        "print(\"Missing após tratamento:\", clima['temperature'].isnull().sum())\n"
      ],
      "metadata": {
        "id": "RmfSSqM4_-oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clima['temperature'] = clima.groupby('region')['temperature'].transform(\n",
        "    lambda x: x.fillna(method='bfill').fillna(method='ffill')\n",
        ")\n"
      ],
      "metadata": {
        "id": "GGl1FZo2_-bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clientes['region'].value_counts()\n"
      ],
      "metadata": {
        "id": "3VubTil5_-Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A região é necessária para integração com dados climáticos e representa apenas 5% da base, opto por exclusão desses clientes para preservar consistência estrutural dos dados."
      ],
      "metadata": {
        "id": "F-1FTkq14kZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clientes = clientes[clientes['region'] != 'Desconhecida']\n",
        "df = consumo.merge(clientes, on='client_id', how='inner')\n",
        "df = df.merge(clima, on=['region','date'], how='left')\n",
        "\n"
      ],
      "metadata": {
        "id": "TLSxnKh1_-PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape final:\", df.shape)\n"
      ],
      "metadata": {
        "id": "FvHAHdmy_-Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "2TLWER7v46oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['client_id'].nunique()\n"
      ],
      "metadata": {
        "id": "Y9-E0SRn46ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "\n",
        "df = df.sort_values(['client_id','date'])\n"
      ],
      "metadata": {
        "id": "s_3_jwzu46il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Features Autoregressivas - Principal Driver\n",
        "\n",
        "df['lag_1'] = df.groupby('client_id')['consumption_kwh'].shift(1)\n",
        "df['lag_7'] = df.groupby('client_id')['consumption_kwh'].shift(7)\n"
      ],
      "metadata": {
        "id": "tvWCYkBb46ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Rolling Mean - Suavização\n",
        "df['rolling_mean_7'] = df.groupby('client_id')['consumption_kwh']\\\n",
        "                           .transform(lambda x: x.rolling(7).mean())\n"
      ],
      "metadata": {
        "id": "xxhsMbab46c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rolling_std_7'] = df.groupby('client_id')['consumption_kwh']\\\n",
        "                          .transform(lambda x: x.rolling(7).std())\n"
      ],
      "metadata": {
        "id": "d-AyL32y46Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features temporais\n",
        "df['temp_squared'] = df['temperature'] ** 2\n",
        "\n"
      ],
      "metadata": {
        "id": "buHC8EU7Sk43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "honsB28VSk1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model = df.dropna().copy()\n"
      ],
      "metadata": {
        "id": "pttV4FRxSkye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns\n",
        "print(df_model.columns)\n"
      ],
      "metadata": {
        "id": "d4z0TXo7Tg4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model = df.dropna().copy()\n"
      ],
      "metadata": {
        "id": "JtjyjPxzSktE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model['date'] = pd.to_datetime(df_model['date'])\n"
      ],
      "metadata": {
        "id": "ihQO0zE9T8KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "features = [\n",
        "    'lag_1',\n",
        "    'lag_7',\n",
        "    'rolling_mean_7',\n",
        "    'rolling_std_7',\n",
        "    'temperature',\n",
        "    'humidity',\n",
        "    'temp_squared',\n",
        "    'month',\n",
        "    'dayofweek'\n",
        "]\n"
      ],
      "metadata": {
        "id": "lgD3kqsfTH-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'consumption_kwh'\n"
      ],
      "metadata": {
        "id": "UB3pqEFgTH7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model['month'] = df_model['date'].dt.month\n",
        "df_model['dayofweek'] = df_model['date'].dt.dayofweek"
      ],
      "metadata": {
        "id": "1gUByfFtUCbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_model.dtypes)\n"
      ],
      "metadata": {
        "id": "wv2XCUfpUJbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Temporal\n",
        "cutoff_date = '2023-06-01'\n",
        "\n",
        "train = df_model[df_model['date'] < cutoff_date]\n",
        "test = df_model[df_model['date'] >= cutoff_date]\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "TZg45RSxTH3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem"
      ],
      "metadata": {
        "id": "lmslq_tkVNtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo 1 — Baseline (Linear Regression)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "pred_lr = lr.predict(X_test)\n",
        "\n",
        "mae_lr = mean_absolute_error(y_test, pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test, pred_lr))\n",
        "\n",
        "print(\"Linear Regression\")\n",
        "print(\"MAE:\", mae_lr)\n",
        "print(\"RMSE:\", rmse_lr)\n"
      ],
      "metadata": {
        "id": "s7NAr1IcTH0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O modelo linear apresentou erro médio absoluto de aproximadamente 1.66 kWh, representando cerca de 11% do consumo médio diário, indicando capacidade preditiva relevante mesmo sob hipótese linear simples."
      ],
      "metadata": {
        "id": "r0vLrrgLWeOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo 2 — Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "pred_rf = rf.predict(X_test)\n",
        "\n",
        "mae_rf = mean_absolute_error(y_test, pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, pred_rf))\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "print(\"MAE:\", mae_rf)\n",
        "print(\"RMSE:\", rmse_rf)\n"
      ],
      "metadata": {
        "id": "KkJXfYaLTHxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### O modelo não linear (Random Forest) não apresentou ganho significativo em relação ao modelo linear, sugerindo que a estrutura do problema é majoritariamente linear e dominada por efeitos autoregressivos."
      ],
      "metadata": {
        "id": "7atgl36sWhfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "importances = pd.Series(rf.feature_importances_, index=features)\n",
        "print(importances.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "dQfsb2voTHuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A variável rolling_mean_7 concentra aproximadamente 88% da importância preditiva no modelo não linear, evidenciando que o consumo recente é o principal determinante do consumo futuro, com influência climática marginal."
      ],
      "metadata": {
        "id": "ahI_kMQnW4yX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conectar ao DuckDB"
      ],
      "metadata": {
        "id": "yIIaZ15lYo__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "con = duckdb.connect(database='aquarela.db', read_only=False)\n"
      ],
      "metadata": {
        "id": "NEOZS6lBTHqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar tabelas\n",
        "con.register(\"df_consumo\", consumo)\n",
        "con.register(\"df_clientes\", clientes)\n",
        "con.register(\"df_clima\", clima)\n"
      ],
      "metadata": {
        "id": "JOuTqNheW7VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con.execute(\"CREATE OR REPLACE TABLE consumo AS SELECT * FROM df_consumo\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE clientes AS SELECT * FROM df_clientes\")\n",
        "con.execute(\"CREATE OR REPLACE TABLE clima AS SELECT * FROM df_clima\")\n"
      ],
      "metadata": {
        "id": "LLMzjMobW7Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferindo tabelas\n",
        "con.execute(\"SHOW TABLES\").fetchall()\n"
      ],
      "metadata": {
        "id": "7r6ww75aW7Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando integrando DuckDB\n",
        "query = \"\"\"\n",
        "CREATE OR REPLACE TABLE consumo_integrado AS\n",
        "SELECT\n",
        "    c.client_id,\n",
        "    c.date,\n",
        "    c.consumption_kwh,\n",
        "    cli.region,\n",
        "    cl.temperature,\n",
        "    cl.humidity\n",
        "FROM consumo c\n",
        "JOIN clientes cli\n",
        "    ON c.client_id = cli.client_id\n",
        "JOIN clima cl\n",
        "    ON cli.region = cl.region\n",
        "   AND c.date = cl.date\n",
        "\"\"\"\n",
        "con.execute(query)\n"
      ],
      "metadata": {
        "id": "LJU3zyJ9W7DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferindo\n",
        "con.execute(\"SELECT COUNT(*) FROM consumo_integrado\").fetchall()\n"
      ],
      "metadata": {
        "id": "7cc7Ymi0THnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(Window function) Feature via SQL\n",
        "query_features = \"\"\"\n",
        "CREATE OR REPLACE TABLE consumo_features AS\n",
        "SELECT *,\n",
        "       LAG(consumption_kwh, 1) OVER (\n",
        "           PARTITION BY client_id\n",
        "           ORDER BY date\n",
        "       ) AS lag_1,\n",
        "\n",
        "       AVG(consumption_kwh) OVER (\n",
        "           PARTITION BY client_id\n",
        "           ORDER BY date\n",
        "           ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
        "       ) AS rolling_mean_7\n",
        "\n",
        "FROM consumo_integrado\n",
        "\"\"\"\n",
        "con.execute(query_features)\n"
      ],
      "metadata": {
        "id": "HC6sBKAhTHkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre processamento"
      ],
      "metadata": {
        "id": "xzhpc1YJDt9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "WQnqUzERD1Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/preprocessing.py\n",
        "\n",
        "import duckdb\n",
        "\n",
        "\n",
        "def create_integrated_table(db_path=\"aquarela.db\"):\n",
        "    con = duckdb.connect(database=db_path, read_only=False)\n",
        "\n",
        "    query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE consumo_integrado AS\n",
        "    SELECT\n",
        "        c.client_id,\n",
        "        c.date,\n",
        "        c.consumption_kwh,\n",
        "        cli.region,\n",
        "        cl.temperature,\n",
        "        cl.humidity\n",
        "    FROM consumo c\n",
        "    JOIN clientes cli\n",
        "        ON c.client_id = cli.client_id\n",
        "    JOIN clima cl\n",
        "        ON cli.region = cl.region\n",
        "       AND c.date = cl.date\n",
        "    \"\"\"\n",
        "\n",
        "    con.execute(query)\n",
        "    con.close()\n",
        "\n",
        "\n",
        "def create_feature_table(db_path=\"aquarela.db\"):\n",
        "    con = duckdb.connect(database=db_path, read_only=False)\n",
        "\n",
        "    query_features = \"\"\"\n",
        "    CREATE OR REPLACE TABLE consumo_features AS\n",
        "    SELECT *,\n",
        "           LAG(consumption_kwh, 1) OVER (\n",
        "               PARTITION BY client_id\n",
        "               ORDER BY date\n",
        "           ) AS lag_1,\n",
        "\n",
        "           AVG(consumption_kwh) OVER (\n",
        "               PARTITION BY client_id\n",
        "               ORDER BY date\n",
        "               ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
        "           ) AS rolling_mean_7\n",
        "\n",
        "    FROM consumo_integrado\n",
        "    \"\"\"\n",
        "\n",
        "    con.execute(query_features)\n",
        "    con.close()\n"
      ],
      "metadata": {
        "id": "oUL23CSND1Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    consumo = pd.read_csv(\"consumo.csv\")\n",
        "    clima = pd.read_csv(\"clima.csv\")\n",
        "    clientes = pd.read_csv(\"clientes.csv\")\n",
        "\n",
        "    consumo[\"date\"] = pd.to_datetime(consumo[\"date\"])\n",
        "    clima[\"date\"] = pd.to_datetime(clima[\"date\"])\n",
        "\n",
        "    return consumo, clima, clientes\n"
      ],
      "metadata": {
        "id": "z8F8033XE9rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/preprocessing.py\n",
        "\n",
        "import duckdb\n",
        "\n",
        "\n",
        "def create_integrated_table(db_path, consumo_df, clientes_df, clima_df):\n",
        "    con = duckdb.connect(database=db_path, read_only=False)\n",
        "\n",
        "    # Register the pandas DataFrames as temporary views in the current connection\n",
        "    con.register(\"consumo\", consumo_df)\n",
        "    con.register(\"clientes\", clientes_df)\n",
        "    con.register(\"clima\", clima_df)\n",
        "\n",
        "    query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE consumo_integrado AS\n",
        "    SELECT\n",
        "        c.client_id,\n",
        "        c.date,\n",
        "        c.consumption_kwh,\n",
        "        cli.region,\n",
        "        cl.temperature,\n",
        "        cl.humidity\n",
        "    FROM consumo c\n",
        "    JOIN clientes cli\n",
        "        ON c.client_id = cli.client_id\n",
        "    JOIN clima cl\n",
        "        ON cli.region = cl.region\n",
        "       AND c.date = cl.date\n",
        "    \"\"\"\n",
        "\n",
        "    con.execute(query)\n",
        "    con.close()\n",
        "\n",
        "\n",
        "def create_feature_table(db_path=\"aquarela.db\"):\n",
        "    con = duckdb.connect(database=db_path, read_only=False)\n",
        "\n",
        "    query_features = \"\"\"\n",
        "    CREATE OR REPLACE TABLE consumo_features AS\n",
        "    SELECT *,\n",
        "           LAG(consumption_kwh, 1) OVER (\n",
        "               PARTITION BY client_id\n",
        "               ORDER BY date\n",
        "           ) AS lag_1,\n",
        "\n",
        "           AVG(consumption_kwh) OVER (\n",
        "               PARTITION BY client_id\n",
        "               ORDER BY date\n",
        "               ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
        "           ) AS rolling_mean_7\n",
        "\n",
        "    FROM consumo_integrado\n",
        "    \"\"\"\n",
        "\n",
        "    con.execute(query_features)\n",
        "    con.close()\n",
        "\n",
        "from src.preprocessing import create_integrated_table, create_feature_table\n",
        "\n",
        "# Pass the global DataFrames to the function\n",
        "create_integrated_table(db_path=\"aquarela.db\", consumo_df=consumo, clientes_df=clientes, clima_df=clima)\n",
        "create_feature_table()\n"
      ],
      "metadata": {
        "id": "S7atdwMnD1Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train.py\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "def train_model(db_path=\"aquarela.db\"):\n",
        "\n",
        "    con = duckdb.connect(database=db_path, read_only=False)\n",
        "    df = con.execute(\"SELECT * FROM consumo_features\").fetchdf()\n",
        "    con.close()\n",
        "\n",
        "    df = df.dropna()\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "    features = [\"lag_1\", \"rolling_mean_7\", \"temperature\", \"humidity\"]\n",
        "    target = \"consumption_kwh\"\n",
        "\n",
        "    cutoff_date = \"2023-06-01\"\n",
        "    train = df[df[\"date\"] < cutoff_date]\n",
        "    test = df[df[\"date\"] >= cutoff_date]\n",
        "\n",
        "    X_train = train[features]\n",
        "    y_train = train[target]\n",
        "\n",
        "    X_test = test[features]\n",
        "    y_test = test[target]\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "\n",
        "    metrics = {\n",
        "        \"MAE\": float(mae),\n",
        "        \"RMSE\": float(rmse)\n",
        "    }\n",
        "\n",
        "    joblib.dump(model, \"models/model_v1.pkl\")\n",
        "\n",
        "    with open(\"models/metrics_v1.json\", \"w\") as f:\n",
        "        json.dump(metrics, f)\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "IIztfmpcD1JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src\n",
        "!mkdir -p models"
      ],
      "metadata": {
        "id": "KIUHhYXlMVUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat src/preprocessing.py\n"
      ],
      "metadata": {
        "id": "ilUvMvH5D1GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmar existencia de tabelas\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect(\"aquarela.db\")\n",
        "print(con.execute(\"SHOW TABLES\").fetchall())\n"
      ],
      "metadata": {
        "id": "qwQskYlcbVki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.train import train_model\n",
        "\n",
        "metrics = train_model()\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "id": "yEe_0MWRbVgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models\n"
      ],
      "metadata": {
        "id": "_sOQloVjbVc6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}